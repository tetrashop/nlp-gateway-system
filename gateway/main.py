"""
Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ BERT Ø§Ø² Ù¾ÛŒØ´ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡.
Ø§ÛŒÙ† Ø³Ø±ÙˆÛŒØ³ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø§Ø®Ù„ÛŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ ØªÙˆØ³Ø· API Gateway ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯.
"""
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch
import logging
from typing import Dict, Any

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª
class SentimentRequest(BaseModel):
    text: str
    truncation: bool = True
    max_length: int = 512

class SentimentResponse(BaseModel):
    sentiment: str
    confidence: float
    label_id: int
    raw_output: Dict[str, Any]

# Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† FastAPI
app = FastAPI(
    title="Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª ÙØ§Ø±Ø³ÛŒ",
    description="Ø³Ø±ÙˆÛŒØ³ Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ HooshvareLab/bert-fa-base-uncased-sentiment",
    version="1.0.0"
)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³
@app.on_event("startup")
async def load_model():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ ØªÙˆÚ©Ù†Ø§ÛŒØ²Ø± Ù‡Ù†Ú¯Ø§Ù… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³"""
    global sentiment_pipeline
    try:
        logger.info("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª ÙØ§Ø±Ø³ÛŒ...")
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø§Ø² Ù¾ÛŒØ´ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª ÙØ§Ø±Ø³ÛŒ
        model_name = "HooshvareLab/bert-fa-base-uncased-sentiment"
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ ØªÙˆÚ©Ù†Ø§ÛŒØ²Ø±
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        
        # Ø§ÛŒØ¬Ø§Ø¯ pipeline Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª
        sentiment_pipeline = pipeline(
            "sentiment-analysis",
            model=model,
            tokenizer=tokenizer,
            device=0 if torch.cuda.is_available() else -1  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GPU Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
        )
        
        logger.info(f"âœ… Ù…Ø¯Ù„ {model_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        logger.info(f"ğŸ“Š Ø¯Ø³ØªÚ¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´: {'GPU' if torch.cuda.is_available() else 'CPU'}")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {e}")
        raise

@app.get("/")
async def root():
    """ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ø³Ø±ÙˆÛŒØ³"""
    return {
        "service": "Sentiment Analysis API",
        "language": "Persian (Farsi)",
        "status": "active",
        "model": "HooshvareLab/bert-fa-base-uncased-sentiment",
        "endpoints": {
            "analyze": "POST /analyze",
            "health": "GET /health",
            "info": "GET /info"
        }
    }

@app.get("/health")
async def health_check():
    """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆÛŒØ³ Ùˆ Ù…Ø¯Ù„"""
    try:
        # ØªØ³Øª Ù…Ø¯Ù„ Ø¨Ø§ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ù†Ù…ÙˆÙ†Ù‡
        test_text = "Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø§Ø³Øª"
        _ = sentiment_pipeline(test_text, truncation=True, max_length=512)
        
        return {
            "status": "healthy",
            "model_loaded": True,
            "service": "sentiment-analysis"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail="Model not ready")

@app.get("/info")
async def model_info():
    """Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡"""
    return {
        "model_name": "HooshvareLab/bert-fa-base-uncased-sentiment",
        "task": "sentiment-analysis",
        "language": "fa",
        "labels": ["negative", "neutral", "positive"],
        "max_length": 512,
        "description": "BERT base uncased model for Persian sentiment analysis"
    }

@app.post("/analyze", response_model=SentimentResponse)
async def analyze_sentiment(request: SentimentRequest):
    """
    ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ ÙˆØ±ÙˆØ¯ÛŒ
    
    Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
    - text: Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
    - truncation: Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ø§Ú¯Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ± Ø§Ø² max_length Ø¨Ø§Ø´Ø¯ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: True)
    - max_length: Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ ØªÙˆÚ©Ù† (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 512)
    
    Ù¾Ø§Ø³Ø®:
    - sentiment: Ø¨Ø±Ú†Ø³Ø¨ Ø§Ø­Ø³Ø§Ø³ (negative/neutral/positive)
    - confidence: Ù…ÛŒØ²Ø§Ù† Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù…Ø¯Ù„ (Ø¨ÛŒÙ† 0 ØªØ§ 1)
    - label_id: Ø´Ù†Ø§Ø³Ù‡ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ú†Ø³Ø¨
    - raw_output: Ø®Ø±ÙˆØ¬ÛŒ Ø®Ø§Ù… Ù…Ø¯Ù„
    """
    try:
        logger.info(f"ğŸ“¨ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª. Ø·ÙˆÙ„ Ù…ØªÙ†: {len(request.text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        
        # ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² pipeline
        result = sentiment_pipeline(
            request.text,
            truncation=request.truncation,
            max_length=request.max_length
        )[0]  # pipeline Ù„ÛŒØ³Øª Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ØŒ Ø§ÙˆÙ„ÛŒÙ† Ø¹Ù†ØµØ± Ø±Ø§ Ø¨Ú¯ÛŒØ±
        
        # Ù†Ú¯Ø§Ø´Øª label Ø¨Ù‡ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø®ÙˆØ§Ù†Ø§
        label_mapping = {
            "LABEL_0": {"fa": "Ù…Ù†ÙÛŒ", "en": "negative", "id": 0},
            "LABEL_1": {"fa": "Ø®Ù†Ø«ÛŒ", "en": "neutral", "id": 1},
            "LABEL_2": {"fa": "Ù…Ø«Ø¨Øª", "en": "positive", "id": 2}
        }
        
        label_info = label_mapping.get(result['label'], {"fa": "Ù†Ø§Ù…Ø´Ø®Øµ", "en": "unknown", "id": -1})
        
        response = SentimentResponse(
            sentiment=label_info["fa"],
            confidence=round(result['score'], 4),
            label_id=label_info["id"],
            raw_output=result
        )
        
        logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. Ù†ØªÛŒØ¬Ù‡: {response.sentiment} (Ø§Ø¹ØªÙ…Ø§Ø¯: {response.confidence})")
        return response
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ†: {str(e)}"
        )

if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸš€ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª ÙØ§Ø±Ø³ÛŒ...")
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        log_level="info"
    )
